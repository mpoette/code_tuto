# Cours IA et Médecine Personnalisée - Structure Complète

## Vue d'ensemble

Ce cours explore la progression méthodologique **des statistiques conventionnelles à la médecine personnalisée**, à travers l'analyse du dataset Framingham Heart Study.

**Durée** : 2 heures (Partie 1 uniquement : 1h15)

**Public** : Étudiants en médecine (3ème année) et pharmacie (4-5ème année)

**Format** : Jupyter notebook interactif avec widgets (pas de code à écrire)

---

## Structure des fichiers

### Fichier 1 : `cours_ia_medecine_partie1_complete.md`

**Contenu** :
- Introduction complète au problème clinique
- Présentation du dataset Framingham
- Sélection du patient témoin (fil rouge)
- **Étape 1** : Tests univariés (Chi², Student) avec widget interactif

**Durée** : 20 minutes

---

### Fichier 2 : `cours_ia_medecine_etapes2_3.md` (À CRÉER)

**Contenu** :
- **Étape 2** : Régression logistique classique
  - Sélection interactive de variables
  - Forest plot des Odds Ratios
  - Courbe ROC
  - Prédiction pour le patient témoin
  
- **Étape 3** : Régression logistique régularisée (Lasso/Ridge)
  - Slider pour lambda (force de régularisation)
  - Visualisation de la sélection de variables
  - Comparaison Lasso vs Ridge

**Durée** : 25 minutes

---

### Fichier 3 : `cours_ia_medecine_etapes4_5_6.md` (À CRÉER)

**Contenu** :
- **Étape 4** : Random Forest
  - Sliders n_estimators, max_depth
  - Feature importance
  - Courbe ROC

- **Étape 5** : XGBoost (Gradient Boosting)
  - Sliders learning_rate, n_estimators
  - Courbe d'apprentissage
  - Calibration plot

- **Étape 6** : Neural Networks
  - Architecture simple (2 couches cachées)
  - Comparaison honnête avec XGBoost
  - Discussion : besoin de gros datasets

**Durée** : 30 minutes

---

### Fichier 4 : `cours_ia_medecine_synthese.md` (À CRÉER)

**Contenu** :
- **Widget comparateur final** : 
  - Affiche les 6 prédictions côte à côte pour le patient témoin
  - Slider pour modifier une variable (ex: arrêt tabac)
  - Voir comment chaque modèle réagit
  
- **Tableau récapitulatif** :
  | Méthode | Interprétabilité | AUC | Variables | Interactions | Temps |
  
- **Arbre décisionnel** : "Quand utiliser quoi ?"

- **IA générative** : Rôle conceptuel (pas d'exécution)

**Durée** : 10 minutes

---

## Progression pédagogique

### Fil conducteur

Un **patient témoin** (M. Dupont ou Mme Martin) traverse toute l'analyse :
- Tirage aléatoire au début
- Chaque méthode calcule son risque
- Comparaison avec l'événement réellement observé

### Questions guidant la progression

| Étape | Question | Réponse | AUC attendu |
|-------|----------|---------|-------------|
| 1. Tests univariés | Une variable suffit ? | Non, trop simpliste | 0.58 |
| 2. Régression logistique | Combiner plusieurs variables ? | Oui, mais linéaire | 0.70 |
| 3. Régularisation | Utiliser toutes les variables ? | Oui, avec sélection auto | 0.72 |
| 4. Random Forest | Capturer les interactions ? | Oui, mais moins interprétable | 0.78 |
| 5. XGBoost | Optimiser davantage ? | Oui, état de l'art | 0.81 |
| 6. Neural Networks | Réseaux profonds meilleurs ? | Non sur petits datasets | 0.79 |

---

## Prérequis techniques

### Installation

```bash
pip install pandas numpy matplotlib seaborn scikit-learn scipy ipywidgets
pip install xgboost  # Pour étape 5
pip install kagglehub  # Optionnel (fallback sur données simulées)
```

### Exécution

**Option 1 : Local**
```bash
jupyter notebook cours_ia_medecine_complete.ipynb
```

**Option 2 : Binder** (recommandé pour les étudiants)
- Upload sur GitHub
- Lien mybinder.org
- Pas d'installation requise

---

## Principes didactiques

### 1. Interactivité maximale
- Chaque étape a son widget
- Pas de code à écrire
- Exploration immédiate

### 2. Comparaison honnête
- Mêmes données pour toutes les méthodes
- Validation croisée systématique
- Pas de biais en faveur d'une approche

### 3. Nuance clinique
- Pas de "miracle de l'IA"
- Neural Networks pas meilleurs ici (petit dataset)
- Chaque méthode a sa place

### 4. Ton académique
- Pas d'émojis
- Terminologie précise
- Références aux concepts statistiques

---

## Métriques d'évaluation

### Performance
- **AUC-ROC** : Discrimination (capacité à séparer risque+ et risque-)
- **Accuracy** : Pourcentage de prédictions correctes
- **Calibration** : Les probabilités prédites sont-elles justes ?

### Interprétabilité
- **Régression logistique** : Très haute (coefficients, OR)
- **Random Forest** : Moyenne (feature importance)
- **XGBoost** : Faible (boîte noire)
- **Neural Networks** : Très faible

### Compromis
Plus on gagne en performance, plus on perd en interprétabilité.

---

## Points d'attention pour l'enseignant

### Sur les Neural Networks
**Soyez honnête** :
- Pas meilleurs que XGBoost sur Framingham (4000 patients)
- Besoin de millions d'exemples pour exceller
- Montrez un exemple où ils brillent (ImageNet, MIMIC-IV)

### Sur l'IA générative
**Clarifiez le rôle** :
- Pas un modèle prédictif, mais une interface
- Appelle XGBoost en backend
- Cas d'usage : explication, chatbot, génération de rapports

### Sur l'EBM vs IA
**Évitez l'opposition** :
- L'IA complète l'EBM, ne la remplace pas
- L'EBM fournit le cadre, l'IA personnalise
- Le clinicien reste central

---

## Adaptation du cours

### Pour 1h (version courte)
- Garder : Étapes 1, 2, 4, 5 + Synthèse
- Retirer : Étapes 3 et 6

### Pour 3h (version longue)
- Ajouter : Partie 2 (Enveloppe convexe, Digital Twins, Data Overload)
- Ajouter : Travaux pratiques en groupes

### Pour pharmacie
- Insister sur : Drug design, essais cliniques, pharmacovigilance
- Ajouter : Exemple prédiction d'interactions médicamenteuses

### Pour médecine
- Insister sur : Diagnostic, aide à la décision clinique
- Ajouter : Exemple détection précoce de sepsis

---

## Ressources complémentaires

### Datasets alternatives
- MIMIC-III/IV : Données de réanimation (50k+ patients)
- UK Biobank : Données génomiques + cliniques (500k+ patients)
- PhysioNet : Signaux physiologiques temps réel

### Outils d'interprétabilité
- SHAP : Contribution de chaque variable pour une prédiction
- LIME : Explication locale de décisions
- Partial Dependence Plots : Effet d'une variable

### Références académiques
- Framingham Heart Study (Kannel et al., 1961)
- Machine Learning in Medicine (Obermeyer & Emanuel, 2016)
- Clinical prediction models (Steyerberg, 2019)

---

## Contact et contributions

**Responsables** :
- Cécile Bon (Pharmacie)
- Fabrice Ferré (Médecine, CHU Toulouse)
- Michael Poette (Anesthésie-Réanimation, CHU Toulouse)

**Université de Toulouse - Faculté de Santé**

Pour suggestions ou corrections : [à compléter]